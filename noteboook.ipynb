{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8592a65",
   "metadata": {},
   "source": [
    "# Expérience 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6694011",
   "metadata": {},
   "source": [
    "## Entrainez un classificateur sur MNIST (Resnet18 poids initiaux aléatoire)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616a73b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdd22223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, random, csv, time \n",
    "import numpy as np\n",
    "from pathlib import Path \n",
    "\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models \n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import InterpolationMode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba0c6e",
   "metadata": {},
   "source": [
    "### **Obtention des données de standardisations** :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03a993",
   "metadata": {},
   "source": [
    "Pour les images du données de jeu de ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9560e44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.485, 0.456, 0.406]\n",
      "[0.229, 0.224, 0.225]\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "print(ResNet18_Weights.IMAGENET1K_V1.transforms().mean)\n",
    "print(ResNet18_Weights.IMAGENET1K_V1.transforms().std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc15052",
   "metadata": {},
   "source": [
    "Pour MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1af78f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moyenne :  0.13066047430038452\n",
      "Std :  0.30810782313346863\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "train_set = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
    "data = torch.cat([x for x, _ in train_set], dim=0)  # concatène toutes les images\n",
    "mean = data.mean().item()\n",
    "std = data.std().item()\n",
    "print(\"Moyenne : \",mean)\n",
    "print(\"Std : \", std)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94eb0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD  = (0.229, 0.224, 0.225)\n",
    "MNIST_MEAN = (0.1307, 0.1307, 0.1307)  # dupliqué sur 3 canaux\n",
    "MNIST_STD  = (0.3081, 0.3081, 0.3081)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e83644",
   "metadata": {},
   "source": [
    "### Définir la seed + device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3a21b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int | None):\n",
    "    \"\"\"\n",
    "    Fixe toutes les graines aléatoires pour garantir la reproductibilité des expériences.\n",
    "\n",
    "    Cette fonction initialise les générateurs de nombres aléatoires utilisés par :\n",
    "      - le module `random` (Python standard)\n",
    "      - `numpy` (opérations et tirages aléatoires)\n",
    "      - `torch` (initialisation des poids, dropout, DataLoader, etc.)\n",
    "      - `torch.cuda` (opérations GPU)\n",
    "\n",
    "    Elle rend également les opérations cuDNN déterministes pour assurer\n",
    "    des résultats identiques sur GPU entre plusieurs exécutions.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    seed : int ou None\n",
    "        - Si un entier est fourni : active le mode déterministe avec cette graine.\n",
    "        - Si None : ne fait rien (l'entraînement reste aléatoire).\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        return\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd837cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624bc1f1",
   "metadata": {},
   "source": [
    "### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef0031f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform(pretrained: bool = True, input_size: int = 32, center_crop: bool = False):\n",
    "    \"\"\"\n",
    "    - input_size : taille finale (ex: 64 ou 96 ou 128)\n",
    "    - center_crop=False : on évite un crop inutile pour MNIST; mets True si tu veux Resize+Crop\n",
    "    - pretrained=True : normalisation ImageNet\n",
    "      pretrained=False: normalisation MNIST (3 canaux)\n",
    "    \"\"\"\n",
    "    ops = []\n",
    "    if center_crop:\n",
    "        # Variante \"classique\" Resize -> CenterCrop (un poil plus lent)\n",
    "        ops += [\n",
    "            transforms.Resize(input_size + input_size // 8, interpolation=InterpolationMode.BILINEAR, antialias=True),\n",
    "            transforms.CenterCrop(input_size),\n",
    "        ]\n",
    "    else:\n",
    "        # Plus rapide: un seul Resize direct à la bonne taille\n",
    "        ops += [\n",
    "            transforms.Resize(input_size, interpolation=InterpolationMode.BILINEAR, antialias=True),\n",
    "        ]\n",
    "\n",
    "    # MNIST est en niveaux de gris: on fait 3 canaux proprement\n",
    "    ops += [\n",
    "        transforms.Grayscale(num_output_channels=3),  # plus propre que lambda x.convert(\"RGB\")\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    "\n",
    "    if pretrained:\n",
    "        ops += [transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)]\n",
    "    else:\n",
    "        ops += [transforms.Normalize(MNIST_MEAN, MNIST_STD)]\n",
    "\n",
    "    return transforms.Compose(ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5683a",
   "metadata": {},
   "source": [
    "### Model + Init weigths + choix optimiseur + choix crit (f° de loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "198bed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter au fur et à mesure que l'on choisira comment initialiser nos poids\n",
    "\n",
    "def init_weights(module: nn.Module, mode: str = \"default\"):\n",
    "    if mode == \"default\":\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3adb8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet18(num_classes = 10, pretrained = False, init_mode = \"default\", freeze_backbone = False):\n",
    "    weigths = models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "    model = models.resnet18(weights = weigths)\n",
    "    in_f = model.fc.in_features\n",
    "    # On regarde à la fin le nb d'entrées attendues par la dernière couche du resnet\n",
    "    # on s'en sert pour remplacer la derniere couche du resnet (1000 classe pour imaganet)\n",
    "    # par la nouvelle couche adaptée à MNIST (donc 10 classes)\n",
    "\n",
    "    model.fc = nn.Linear(in_f, num_classes)\n",
    "\n",
    "    if freeze_backbone : \n",
    "        for name, p in model.named_parameters():\n",
    "            if not name.startswith(\"fc.\"):\n",
    "                p.requires_grad = False\n",
    "        \n",
    "    if init_mode == \"head_only\":\n",
    "        init_weights(model.fc, mode = \"default\")\n",
    "    elif init_mode in {}:\n",
    "        model.apply(lambda m: init_weights(m, init_mode))\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b41e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(name: str, params, lr: float, weight_decay: float = 0.0):\n",
    "    \"\"\"\n",
    "    Crée un optimiseur à partir de son nom.\n",
    "    Exemples  :\n",
    "      - SGD\n",
    "      - Adam/AdamW\n",
    "      - RMSprop\n",
    "      - rmsprop \n",
    "      - adagrad\n",
    "    \"\"\"\n",
    "    n = name.lower()\n",
    "    if n == \"adamw\":\n",
    "        return optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "    if n == \"adam\":\n",
    "        return optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    if n == \"sgd\":\n",
    "        return optim.SGD(params, lr=lr, weight_decay=weight_decay)\n",
    "    if n == \"rmsprop\":\n",
    "        return optim.RMSprop(params, lr=lr, weight_decay=weight_decay)\n",
    "    if n == \"adagrad\":\n",
    "        return optim.Adagrad(params, lr=lr, weight_decay=weight_decay)\n",
    "    raise ValueError(f\"Optimiseur inconnu: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc120436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_criterion(name: str):\n",
    "    \"\"\"\n",
    "    Crée une loss de classification à partir de son nom.\n",
    "    Exempless:\n",
    "      - CrossEntropyLoss\n",
    "      - \n",
    "    \"\"\"\n",
    "    n = name.lower()\n",
    "    if n in (\"crossentropy\", \"crossentropyloss\", \"ce\"):\n",
    "        return nn.CrossEntropyLoss()\n",
    "    raise ValueError(f\"Loss inconnue: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2522770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scheduler(name: str, optimizer, epochs: int):\n",
    "    n = name.lower()\n",
    "\n",
    "    if n == \"step\":\n",
    "        return torch.optim.lr_scheduler.StepLR(optimizer, step_size=epochs // 3, gamma=0.1)\n",
    "    # gamma : facteur de réduction \n",
    "\n",
    "\n",
    "\n",
    "    if n == \"cosine\":\n",
    "        return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    if n == \"none\":\n",
    "        return None\n",
    "\n",
    "    raise ValueError(f\"Scheduler inconnu: {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373ef23",
   "metadata": {},
   "source": [
    "### Boucles entrainement / evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d523e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion): \n",
    "    model.eval()\n",
    "    loss_sum =0.0; correct = 0; total = 0\n",
    "    for x, y in loader :\n",
    "        x,y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss_sum+=loss.item()*x.size(0)\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return loss_sum/total, correct/total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23959453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(\n",
    "\n",
    "    pretrained=False,             # True = poids ImageNet + normalisation ImageNet\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    seed=42,                      # None pour laisser aléatoire (utile pour l'ensemble)\n",
    "    data_dir=\"./data\",\n",
    "    out_dir=\"./runs\",\n",
    "    save_tag=None,\n",
    "    # nouveau : init & freeze\n",
    "    init_mode=\"default\",          # 'default' pour l'instant que ça mais à améliorer pour offrir différentes initialisation de poids\n",
    "    freeze_backbone=False,        # gèle le backbone (pré-entraîné) et n'entraîne que la tête\n",
    "    shuffle = True ,\n",
    "    optimiseur = \"AdamW\", \n",
    "    criterion = \"CrossEntropyLoss\",\n",
    "    schedular = \"none\"              # activer un scheduler ou non : \"step\" | \"cosine\" | \"none\" | par défaut None\n",
    "):\n",
    "\n",
    "    set_seed(seed)\n",
    "\n",
    "\n",
    "    # Partie Data \n",
    "\n",
    "    tf = build_transform(pretrained)\n",
    "    train_set = datasets.MNIST(data_dir, train = True, download = True, transform = tf)\n",
    "    test_set = datasets.MNIST(data_dir, train = False, download = False, transform =tf)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle = shuffle, num_workers = 0 , pin_memory=False)\n",
    "    test_loader  = DataLoader(test_set,  batch_size=256, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Partie model \n",
    "    model = build_resnet18(\n",
    "        num_classes = 10,\n",
    "        pretrained = pretrained,\n",
    "        init_mode = init_mode, \n",
    "        freeze_backbone=freeze_backbone\n",
    "\n",
    "    ).to(DEVICE)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt = make_optimizer(optimiseur, params, lr, weight_decay)\n",
    "    crit = make_criterion(criterion)\n",
    "    sched = make_scheduler(schedular, opt, epochs)\n",
    "\n",
    "\n",
    "\n",
    "    # logs \n",
    "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tag = save_tag or f\"resnet18_{'pre' if pretrained else 'scratch'}_{init_mode}{'_frozen' if freeze_backbone else ''}_{ts}\"\n",
    "    run_dir = Path(out_dir)/tag; run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    csv_path = run_dir/\"metrics.csv\"\n",
    "    with open(csv_path,\"w\",newline=\"\") as f: csv.writer(f).writerow([\"epoch\",\"train_loss\",\"train_acc\",\"val_loss\",\"val_acc\"])\n",
    "    best_path = run_dir/\"best.pt\"; last_path = run_dir/\"last.pt\"\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Boucle d'entrainement \n",
    "    for ep in range(1, epochs+1):\n",
    "        print(\"Début de l'epochs : \",ep)\n",
    "        model.train(); run_loss =0.0; run_corr=0; run_tot = 0\n",
    "        for x, y in train_loader : \n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = crit(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            \n",
    "            run_loss += loss.item()*x.size(0)\n",
    "            run_corr += (logits.argmax(1) == y).sum().item()\n",
    "            run_tot += x.size(0)\n",
    "\n",
    "\n",
    "   \n",
    "        tl, ta = run_loss/run_tot, run_corr/run_tot\n",
    "        vl, va = evaluate(model, test_loader, crit)\n",
    "\n",
    "        if sched is not None :\n",
    "            sched.step()\n",
    "        with open(csv_path,\"a\",newline=\"\") as f: csv.writer(f).writerow([ep,f\"{tl:.6f}\",f\"{ta:.4f}\",f\"{vl:.6f}\",f\"{va:.4f}\"])\n",
    "        if va>best_acc:\n",
    "            best_acc=va\n",
    "            torch.save({\"state_dict\":model.state_dict(),\n",
    "                        \"pretrained\":pretrained,\n",
    "                        \"init_mode\":init_mode,\n",
    "                        \"freeze_backbone\":freeze_backbone}, best_path)\n",
    "        torch.save({\"state_dict\":model.state_dict(),\n",
    "                    \"pretrained\":pretrained,\n",
    "                    \"init_mode\":init_mode,\n",
    "                    \"freeze_backbone\":freeze_backbone}, last_path)\n",
    "        print(f\"[{ep:02d}/{epochs}] train_loss={tl:.4f} acc={ta:.4f} | val_loss={vl:.4f} acc={va:.4f}\")\n",
    "\n",
    "    print(f\"Best val acc={best_acc:.4f} | best ckpt={best_path}\")\n",
    "    return str(best_path), str(csv_path)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad3f88b",
   "metadata": {},
   "source": [
    "### Récupértion des données de MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c3abe",
   "metadata": {},
   "source": [
    "## Expérience 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f9b18fea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Début de l'epochs :  1\n",
      "[01/10] train_loss=0.8793 acc=0.7210 | val_loss=0.7229 acc=0.7771\n",
      "Début de l'epochs :  2\n",
      "[02/10] train_loss=0.7613 acc=0.7582 | val_loss=0.6941 acc=0.7905\n",
      "Début de l'epochs :  3\n",
      "[03/10] train_loss=0.7496 acc=0.7623 | val_loss=0.7025 acc=0.7864\n",
      "Début de l'epochs :  4\n",
      "[04/10] train_loss=0.7436 acc=0.7663 | val_loss=0.7413 acc=0.7699\n",
      "Début de l'epochs :  5\n",
      "[05/10] train_loss=0.7373 acc=0.7676 | val_loss=0.6858 acc=0.7938\n",
      "Début de l'epochs :  6\n",
      "[06/10] train_loss=0.7369 acc=0.7677 | val_loss=0.6770 acc=0.7953\n",
      "Début de l'epochs :  7\n",
      "[07/10] train_loss=0.7376 acc=0.7688 | val_loss=0.7253 acc=0.7790\n",
      "Début de l'epochs :  8\n",
      "[08/10] train_loss=0.7284 acc=0.7709 | val_loss=0.6818 acc=0.7902\n",
      "Début de l'epochs :  9\n",
      "[09/10] train_loss=0.7354 acc=0.7678 | val_loss=0.6846 acc=0.7930\n",
      "Début de l'epochs :  10\n",
      "[10/10] train_loss=0.7331 acc=0.7691 | val_loss=0.7505 acc=0.7685\n",
      "Best val acc=0.7953 | best ckpt=runs\\fast_headonly_pretrained\\best.pt\n"
     ]
    }
   ],
   "source": [
    "ckpt, log = run_train(\n",
    "    pretrained=True,\n",
    "    freeze_backbone=True,\n",
    "    init_mode=\"head_only\",\n",
    "    epochs=10,\n",
    "    batch_size=64,          # 64 sur CPU est souvent plus fluide que 128\n",
    "    lr=2e-3,\n",
    "    weight_decay=1e-4,\n",
    "    optimiseur=\"AdamW\",\n",
    "    criterion=\"CrossEntropyLoss\",\n",
    "    save_tag=\"fast_headonly_pretrained\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63eab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965d378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uncertainly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
