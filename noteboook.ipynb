{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8592a65",
   "metadata": {},
   "source": [
    "# Expérience 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6694011",
   "metadata": {},
   "source": [
    "## Entrainez un classificateur sur MNIST (Resnet18 poids initiaux aléatoire)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616a73b",
   "metadata": {},
   "source": [
    "### Imports + DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd22223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, random, csv, time\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, models\n",
    "from tqdm import tqdm\n",
    "from torchvision.transforms import InterpolationMode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a545dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17ea106b",
   "metadata": {},
   "source": [
    "### Boîte à outils (affichage, load metrics, load_model, ect...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4c355d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_metrics(run_dir: str | Path) -> pd.DataFrame:\n",
    "    \"\"\"Charge runs/<run_dir>/metrics.csv et retourne un DataFrame avec une colonne epoch entière.\"\"\"\n",
    "    run_dir = Path(run_dir)\n",
    "    df = pd.read_csv(run_dir / \"metrics.csv\")\n",
    "    if \"epoch\" in df.columns:\n",
    "        df[\"epoch\"] = df[\"epoch\"].astype(int)\n",
    "    return df\n",
    "\n",
    "\n",
    "def _pretty_metric_name(metric: str) -> str:\n",
    "    pretty = {\n",
    "        \"train_loss\": \"Train Loss\",\n",
    "        \"val_loss\": \"Val Loss\",\n",
    "        \"train_acc\": \"Train Accuracy\",\n",
    "        \"val_acc\": \"Val Accuracy\",\n",
    "    }\n",
    "    return pretty.get(metric, metric)\n",
    "\n",
    "\n",
    "def plot_metric_across_runs(\n",
    "    run_dirs: list[str | Path],\n",
    "    labels: list[str] | None = None,\n",
    "    metric: str = \"val_acc\",\n",
    "    title: str | None = None,\n",
    "    smooth_window: int | None = None,\n",
    "    save_path: str | Path | None = None,\n",
    "    show: bool = True,\n",
    "    figsize=(9, 5),\n",
    "    linewidth: float = 2.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trace une métrique unique (ex: 'val_acc') pour plusieurs runs.\n",
    "    - smooth_window: taille de fenêtre (int) pour une moyenne glissante simple. None = pas de lissage.\n",
    "    - AUCUNE couleur spécifiée (on laisse Matplotlib choisir).\n",
    "    \"\"\"\n",
    "    assert len(run_dirs) > 0, \"Aucun run fourni.\"\n",
    "    if labels is None:\n",
    "        labels = [Path(d).name for d in run_dirs]\n",
    "    assert len(labels) == len(run_dirs), (\n",
    "        \"labels et run_dirs doivent avoir la même longueur.\"\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for run_dir, lab in zip(run_dirs, labels):\n",
    "        df = load_metrics(run_dir)\n",
    "        if \"epoch\" not in df.columns or metric not in df.columns:\n",
    "            raise ValueError(\n",
    "                f\"Colonnes manquantes dans {run_dir}: attendu 'epoch' et '{metric}'\"\n",
    "            )\n",
    "\n",
    "        x = df[\"epoch\"]\n",
    "        y = df[metric].copy()\n",
    "\n",
    "        if smooth_window is not None and smooth_window > 1:\n",
    "            y = y.rolling(window=smooth_window, min_periods=1, center=False).mean()\n",
    "\n",
    "        plt.plot(x, y, label=lab, linewidth=linewidth)\n",
    "\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(_pretty_metric_name(metric))\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    if save_path:\n",
    "        save_path = Path(save_path)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        plt.savefig(save_path, dpi=200, bbox_inches=\"tight\")\n",
    "    if show:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5264f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path_best_model, num_classes=10):\n",
    "    ckpt = torch.load(path_best_model, map_location=DEVICE)\n",
    "    pretrained = ckpt.get(\"pretrained\", False)\n",
    "    init_mode = ckpt.get(\"init_mode\", \"default\")\n",
    "    freeze_backbone = ckpt.get(\"freeze_backbone\", False)\n",
    "\n",
    "    from torchvision import models\n",
    "\n",
    "    model = models.resnet18(\n",
    "        weights=models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "    )\n",
    "    in_f = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(in_f, num_classes)\n",
    "\n",
    "    model.load_state_dict(ckpt[\"state_dict\"])\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    print(f\"Modèle chargé depuis : {path_best_model}\")\n",
    "    return model, pretrained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ba0c6e",
   "metadata": {},
   "source": [
    "### **Obtention des données de standardisations** :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb03a993",
   "metadata": {},
   "source": [
    "Pour les images du données de jeu de ImageNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560e44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import ResNet18_Weights\n",
    "\n",
    "print(ResNet18_Weights.IMAGENET1K_V1.transforms().mean)\n",
    "print(ResNet18_Weights.IMAGENET1K_V1.transforms().std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc15052",
   "metadata": {},
   "source": [
    "Pour MNIST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af78f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "\n",
    "train_set = datasets.MNIST(\n",
    "    \"./data\", train=True, download=True, transform=transforms.ToTensor()\n",
    ")\n",
    "data = torch.cat([x for x, _ in train_set], dim=0)  # concatène toutes les images\n",
    "mean = data.mean().item()\n",
    "std = data.std().item()\n",
    "print(\"Moyenne : \", mean)\n",
    "print(\"Std : \", std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eb0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGENET_MEAN = (0.485, 0.456, 0.406)\n",
    "IMAGENET_STD = (0.229, 0.224, 0.225)\n",
    "MNIST_MEAN = (0.1307, 0.1307, 0.1307)  # dupliqué sur 3 canaux\n",
    "MNIST_STD = (0.3081, 0.3081, 0.3081)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e83644",
   "metadata": {},
   "source": [
    "### Définir la seed + device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a21b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed: int | None):\n",
    "    \"\"\"\n",
    "    Fixe toutes les graines aléatoires pour garantir la reproductibilité des expériences.\n",
    "\n",
    "    Cette fonction initialise les générateurs de nombres aléatoires utilisés par :\n",
    "      - le module `random` (Python standard)\n",
    "      - `numpy` (opérations et tirages aléatoires)\n",
    "      - `torch` (initialisation des poids, dropout, DataLoader, etc.)\n",
    "      - `torch.cuda` (opérations GPU)\n",
    "\n",
    "    Elle rend également les opérations cuDNN déterministes pour assurer\n",
    "    des résultats identiques sur GPU entre plusieurs exécutions.\n",
    "\n",
    "    Paramètres\n",
    "    ----------\n",
    "    seed : int ou None\n",
    "        - Si un entier est fourni : active le mode déterministe avec cette graine.\n",
    "        - Si None : ne fait rien (l'entraînement reste aléatoire).\n",
    "    \"\"\"\n",
    "    if seed is None:\n",
    "        return\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624bc1f1",
   "metadata": {},
   "source": [
    "### Transform Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0031f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_transform(\n",
    "    pretrained: bool = True, input_size: int = 32, center_crop: bool = False\n",
    "):\n",
    "    \"\"\"\n",
    "    - input_size : taille finale (ex: 64 ou 96 ou 128)\n",
    "    - center_crop=False : on évite un crop inutile pour MNIST; mets True si tu veux Resize+Crop\n",
    "    - pretrained=True : normalisation ImageNet\n",
    "      pretrained=False: normalisation MNIST (3 canaux)\n",
    "    \"\"\"\n",
    "    ops = []\n",
    "    if center_crop:\n",
    "        ops += [\n",
    "            transforms.Resize(\n",
    "                input_size + input_size // 8,\n",
    "                interpolation=InterpolationMode.BILINEAR,\n",
    "                antialias=True,\n",
    "            ),\n",
    "            transforms.CenterCrop(input_size),\n",
    "        ]\n",
    "    else:\n",
    "        ops += [\n",
    "            transforms.Resize(\n",
    "                input_size, interpolation=InterpolationMode.BILINEAR, antialias=True\n",
    "            ),\n",
    "        ]\n",
    "\n",
    "    # MNIST est en niveaux de gris: on fait 3 canaux proprement\n",
    "    ops += [\n",
    "        transforms.Grayscale(\n",
    "            num_output_channels=3\n",
    "        ),  # plus propre que lambda x.convert(\"RGB\")\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    "\n",
    "    if pretrained:\n",
    "        ops += [transforms.Normalize(IMAGENET_MEAN, IMAGENET_STD)]\n",
    "    else:\n",
    "        ops += [transforms.Normalize(MNIST_MEAN, MNIST_STD)]\n",
    "\n",
    "    return transforms.Compose(ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf5683a",
   "metadata": {},
   "source": [
    "### Model + Init weigths + choix optimiseur + choix crit (f° de loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198bed62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A compléter au fur et à mesure que l'on choisira comment initialiser nos poids\n",
    "def init_weights(module: nn.Module, mode: str = \"default\"):\n",
    "    # default = ne rien toucher (poids pré-entraînés ou init PyTorch)\n",
    "    if mode == \"default\":\n",
    "        return\n",
    "\n",
    "    if isinstance(module, (nn.Conv2d, nn.Linear)):\n",
    "        if mode == \"kaiming\":\n",
    "            nn.init.kaiming_normal_(module.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "        elif mode == \"xavier\":\n",
    "            nn.init.xavier_uniform_(module.weight)\n",
    "        elif mode == \"orthogonal\":\n",
    "            nn.init.orthogonal_(module.weight, gain=1.0)\n",
    "        else:\n",
    "            raise ValueError(f\"init_mode inconnu pour init_weights: {mode}\")\n",
    "        if module.bias is not None:\n",
    "            nn.init.zeros_(module.bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb8548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_resnet18(\n",
    "    num_classes=10, pretrained=False, init_mode=\"default\", freeze_backbone=False\n",
    "):\n",
    "    weigths = models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
    "    model = models.resnet18(weights=weigths)\n",
    "    in_f = model.fc.in_features\n",
    "    # On regarde à la fin le nb d'entrées attendues par la dernière couche du resnet\n",
    "    # on s'en sert pour remplacer la derniere couche du resnet (1000 classe pour imaganet)\n",
    "    # par la nouvelle couche adaptée à MNIST (donc 10 classes)\n",
    "\n",
    "    model.fc = nn.Linear(in_f, num_classes)\n",
    "\n",
    "    # option geler le backbone\n",
    "    if freeze_backbone:\n",
    "        for name, p in model.named_parameters():\n",
    "            if not name.startswith(\"fc.\"):\n",
    "                p.requires_grad = False\n",
    "\n",
    "    if init_mode == \"head_only\":\n",
    "        # Ne reinitialise que la tête\n",
    "        init_weights(model.fc, mode=\"xavier\")\n",
    "    elif init_mode in {\"kaiming\", \"xavier\", \"orthogonal\"}:\n",
    "        # reinitialise tout le réseau (quand pretrained = False)\n",
    "        # kaiming totalement alétoire\n",
    "        model.apply(lambda m: init_weights(m, init_mode))\n",
    "    elif init_mode == \"default\":\n",
    "        pass\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"init_mode inconnu : {init_mode}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b41e5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_optimizer(name: str, params, lr: float, weight_decay: float = 0.0):\n",
    "    \"\"\"\n",
    "    Crée un optimiseur à partir de son nom.\n",
    "    Exemples  :\n",
    "      - SGD\n",
    "      - Adam/AdamW\n",
    "      - RMSprop\n",
    "      - rmsprop\n",
    "      - adagrad\n",
    "    \"\"\"\n",
    "    n = name.lower()\n",
    "    if n == \"adamw\":\n",
    "        return optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
    "    if n == \"adam\":\n",
    "        return optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
    "    if n == \"sgd\":\n",
    "        return optim.SGD(params, lr=lr, weight_decay=weight_decay)\n",
    "    if n == \"rmsprop\":\n",
    "        return optim.RMSprop(params, lr=lr, weight_decay=weight_decay)\n",
    "    if n == \"adagrad\":\n",
    "        return optim.Adagrad(params, lr=lr, weight_decay=weight_decay)\n",
    "    raise ValueError(f\"Optimiseur inconnu: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc120436",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_criterion(name: str):\n",
    "    \"\"\"\n",
    "    Crée une loss de classification à partir de son nom.\n",
    "    Exempless:\n",
    "      - CrossEntropyLoss\n",
    "      -\n",
    "    \"\"\"\n",
    "    n = name.lower()\n",
    "    if n in (\"crossentropy\", \"crossentropyloss\", \"ce\"):\n",
    "        return nn.CrossEntropyLoss()\n",
    "    raise ValueError(f\"Loss inconnue: {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2522770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_scheduler(name: str, optimizer, epochs: int):\n",
    "    n = name.lower()\n",
    "\n",
    "    if n == \"step\":\n",
    "        return torch.optim.lr_scheduler.StepLR(\n",
    "            optimizer, step_size=epochs // 3, gamma=0.5\n",
    "        )\n",
    "    # gamma : facteur de réduction\n",
    "\n",
    "    if n == \"cosine\":\n",
    "        return torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "    if n == \"none\":\n",
    "        return None\n",
    "\n",
    "    raise ValueError(f\"Scheduler inconnu: {name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a373ef23",
   "metadata": {},
   "source": [
    "### Boucles entrainement / evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d523e3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    loss_sum = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits = model(x)\n",
    "        loss = criterion(logits, y)\n",
    "        loss_sum += loss.item() * x.size(0)\n",
    "        correct += (logits.argmax(1) == y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return loss_sum / total, correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23959453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train(\n",
    "    pretrained=False,  # True = poids ImageNet + normalisation ImageNet\n",
    "    epochs=10,\n",
    "    batch_size=128,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    seed=42,  # None pour laisser aléatoire (utile pour l'ensemble)\n",
    "    data_dir=\"./data\",\n",
    "    out_dir=\"./runs\",\n",
    "    save_tag=None,\n",
    "    # nouveau : init & freeze\n",
    "    init_mode=\"head_only\",  # si pretrained -> plutot : \"head_only\" initialisation des poids du modele : 'default' | \"head_only\" | \"xavier\" | \"orthogonal\" | \"kaiming\"\n",
    "    freeze_backbone=False,  # gèle le backbone (pré-entraîné) et n'entraîne que la tête\n",
    "    shuffle=True,\n",
    "    optimiseur=\"AdamW\",\n",
    "    criterion=\"CrossEntropyLoss\",\n",
    "    schedular=\"none\",  # activer un scheduler ou non : \"step\" | \"cosine\" | \"none\" | par défaut None\n",
    "):\n",
    "    set_seed(seed)\n",
    "\n",
    "    # Partie Data\n",
    "\n",
    "    tf = build_transform(pretrained)\n",
    "    train_set = datasets.MNIST(data_dir, train=True, download=True, transform=tf)\n",
    "    test_set = datasets.MNIST(data_dir, train=False, download=False, transform=tf)\n",
    "    train_loader = DataLoader(\n",
    "        train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "        pin_memory=False,\n",
    "    )\n",
    "    test_loader = DataLoader(\n",
    "        test_set, batch_size=256, shuffle=False, num_workers=0, pin_memory=False\n",
    "    )\n",
    "\n",
    "    # 60000/10000 : train/test\n",
    "    ## On peut vérifier avec\n",
    "    # print(len(test_set))\n",
    "    # print(len(train_set))\n",
    "\n",
    "    # Partie model\n",
    "    model = build_resnet18(\n",
    "        num_classes=10,\n",
    "        pretrained=pretrained,\n",
    "        init_mode=init_mode,\n",
    "        freeze_backbone=freeze_backbone,\n",
    "    ).to(DEVICE)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    opt = make_optimizer(optimiseur, params, lr, weight_decay)\n",
    "    crit = make_criterion(criterion)\n",
    "    sched = make_scheduler(schedular, opt, epochs)\n",
    "\n",
    "    # logs\n",
    "    ts = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tag = (\n",
    "        save_tag\n",
    "        or f\"resnet18_{'pre' if pretrained else 'scratch'}_{init_mode}{'_frozen' if freeze_backbone else ''}_{ts}\"\n",
    "    )\n",
    "    run_dir = Path(out_dir) / tag\n",
    "    run_dir.mkdir(parents=True, exist_ok=True)\n",
    "    csv_path = run_dir / \"metrics.csv\"\n",
    "    with open(csv_path, \"w\", newline=\"\") as f:\n",
    "        csv.writer(f).writerow(\n",
    "            [\"epoch\", \"train_loss\", \"train_acc\", \"val_loss\", \"val_acc\"]\n",
    "        )\n",
    "    best_path = run_dir / \"best.pt\"\n",
    "    last_path = run_dir / \"last.pt\"\n",
    "    best_acc = 0.0\n",
    "\n",
    "    # Boucle d'entrainement\n",
    "    for ep in range(1, epochs + 1):\n",
    "        print(\"Début de l'epochs : \", ep)\n",
    "        model.train()\n",
    "        run_loss = 0.0\n",
    "        run_corr = 0\n",
    "        run_tot = 0\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "            opt.zero_grad()\n",
    "            logits = model(x)\n",
    "            loss = crit(logits, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            run_loss += loss.item() * x.size(0)\n",
    "            run_corr += (logits.argmax(1) == y).sum().item()\n",
    "            run_tot += x.size(0)\n",
    "\n",
    "        tl, ta = run_loss / run_tot, run_corr / run_tot\n",
    "        vl, va = evaluate(model, test_loader, crit)\n",
    "\n",
    "        if sched is not None:\n",
    "            sched.step()\n",
    "        with open(csv_path, \"a\", newline=\"\") as f:\n",
    "            csv.writer(f).writerow(\n",
    "                [ep, f\"{tl:.6f}\", f\"{ta:.4f}\", f\"{vl:.6f}\", f\"{va:.4f}\"]\n",
    "            )\n",
    "        if va > best_acc:\n",
    "            best_acc = va\n",
    "            torch.save(\n",
    "                {\n",
    "                    \"state_dict\": model.state_dict(),\n",
    "                    \"pretrained\": pretrained,\n",
    "                    \"init_mode\": init_mode,\n",
    "                    \"freeze_backbone\": freeze_backbone,\n",
    "                },\n",
    "                best_path,\n",
    "            )\n",
    "        torch.save(\n",
    "            {\n",
    "                \"state_dict\": model.state_dict(),\n",
    "                \"pretrained\": pretrained,\n",
    "                \"init_mode\": init_mode,\n",
    "                \"freeze_backbone\": freeze_backbone,\n",
    "            },\n",
    "            last_path,\n",
    "        )\n",
    "        print(\n",
    "            f\"[{ep:02d}/{epochs}] train_loss={tl:.4f} acc={ta:.4f} | val_loss={vl:.4f} acc={va:.4f}\"\n",
    "        )\n",
    "\n",
    "    print(f\"Best val acc={best_acc:.4f} | best ckpt={best_path}\")\n",
    "    return str(best_path), str(csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3c3abe",
   "metadata": {},
   "source": [
    "# Expérience 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a27382d",
   "metadata": {},
   "source": [
    "## Entrainements des trois différents modéles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b2f26c",
   "metadata": {},
   "source": [
    "**Resnet pre-trained head_only:**\n",
    "\n",
    "- Entraînement sur la tete de classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b18fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path, log = run_train(\n",
    "    pretrained=True,\n",
    "    freeze_backbone=True,\n",
    "    init_mode=\"head_only\",\n",
    "    epochs=20,\n",
    "    batch_size=64,  # 64 sur CPU + fluide que 128 : si GPU monter\n",
    "    lr=2e-3,\n",
    "    weight_decay=1e-4,\n",
    "    optimiseur=\"AdamW\",\n",
    "    criterion=\"CrossEntropyLoss\",\n",
    "    save_tag=f\"headonly_pretrained_20_epochs_noSched_lr2E3_ADAMW_freezeBackbone\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddb4d40",
   "metadata": {},
   "source": [
    "**Resnet pre-trained - No freeze Backbone :**\n",
    "\n",
    "- Entrainement sur tout le réseau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac63eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path, log = run_train(\n",
    "    pretrained=True,\n",
    "    freeze_backbone=False,\n",
    "    init_mode=\"head_only\",\n",
    "    epochs=3,\n",
    "    batch_size=64,\n",
    "    lr=2e-3,\n",
    "    weight_decay=1e-4,\n",
    "    optimiseur=\"AdamW\",\n",
    "    criterion=\"CrossEntropyLoss\",\n",
    "    save_tag=\"headonly_pretrained_epochs3_noSched_lr2E3_ADAMW_NofreezeBackbone\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4021d715",
   "metadata": {},
   "source": [
    "**Resnet default weight - Random init**\n",
    "\n",
    "- Resnet18 non pré-entrainé\n",
    "- initialisation des poids aléatoire (kaiming)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c965d378",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_path, log = run_train(\n",
    "    pretrained=False,\n",
    "    freeze_backbone=False,\n",
    "    init_mode=\"kaiming\",\n",
    "    epochs=10,\n",
    "    batch_size=64,\n",
    "    lr=2e-3,\n",
    "    weight_decay=1e-4,\n",
    "    optimiseur=\"AdamW\",\n",
    "    criterion=\"CrossEntropyLoss\",\n",
    "    save_tag=\"kaiming_NoPreTrained_epochs20_noSched_lr2E3_ADAMW_\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cf343c",
   "metadata": {},
   "source": [
    "## Résultat :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3320bd",
   "metadata": {},
   "source": [
    "### Courbes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5774e958",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs_root = Path(\"./runs\")\n",
    "run1 = runs_root / \"headonly_pretrained_20_epochs_noSched_lr2E3_ADAMW_freezeBackbone\"\n",
    "run2 = runs_root / \"headonly_pretrained_epochs3_noSched_lr2E3_ADAMW_NofreezeBackbone\"\n",
    "run3 = runs_root / \"kaiming_NoPreTrained_epochs20_noSched_lr2E3_ADAMW_\"\n",
    "\n",
    "plot_metric_across_runs(\n",
    "    run_dirs=[run1, run2, run3],\n",
    "    labels=[\n",
    "        \"Pretrained • Head only • Frozen\",\n",
    "        \"Pretrained • Full FT\",\n",
    "        \"Scratch • Kaiming\",\n",
    "    ],\n",
    "    metric=\"val_acc\",  # ou \"val_loss\", \"train_acc\", etc.\n",
    "    title=\"MNIST – Validation Accuracy (3 variantes ResNet18)\",\n",
    "    smooth_window=1,  # ex. 3 ou 5 pour lisser un peu\n",
    "    save_path=\"./runs/fig_val_acc_3runs.png\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d176d0da",
   "metadata": {},
   "source": [
    "### Predictions des modeles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39fcec2f",
   "metadata": {},
   "source": [
    "#### Fonctions d'affichage de 20 images du dataset + label attribué par le model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a6d936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CHARGEMENT DU DATASET ---\n",
    "def get_mnist_loader(pretrained: bool, data_dir=\"./data\"):\n",
    "    tf = build_transform(pretrained)\n",
    "    dataset = datasets.MNIST(data_dir, train=False, download=True, transform=tf)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# --- AFFICHAGE DE 20 IMAGES AVEC PREDICTIONS ---\n",
    "def show_random_predictions(model, dataset, pretrained, n=20):\n",
    "    indices = random.sample(range(len(dataset)), n)\n",
    "    samples = [dataset[i] for i in indices]\n",
    "    images, labels = zip(*samples)\n",
    "    x = torch.stack(images).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = model(x)\n",
    "        preds = logits.argmax(1).cpu()\n",
    "\n",
    "    # on repasse en numpy pour affichage (re-normalisation simple)\n",
    "    imgs = x.cpu()\n",
    "    imgs = imgs.permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    for i in range(n):\n",
    "        plt.subplot(4, 5, i + 1)\n",
    "        img = imgs[i]\n",
    "        # remet dans [0,1] pour affichage sans dénormaliser complètement\n",
    "        img = (img - img.min()) / (img.max() - img.min() + 1e-6)\n",
    "        plt.imshow(img)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"T:{labels[i]} / P:{preds[i]}\", fontsize=10)\n",
    "    plt.suptitle(\"MNIST – Vrai label (T) / Prédiction (P)\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867adbca",
   "metadata": {},
   "source": [
    "#### Prediction model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a7167",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_best_model = \"./runs/headonly_pretrained_epochs3_noSched_lr2E3_ADAMW_NofreezeBackbone/best.pt\"  # à adapter\n",
    "model, pretrained = load_model(path_best_model)\n",
    "dataset = get_mnist_loader(pretrained)\n",
    "\n",
    "show_random_predictions(model, dataset, pretrained, n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3767881",
   "metadata": {},
   "source": [
    "# Expérience 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027f8fc3",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
